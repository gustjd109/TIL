# 14 가상 메모리

## 1. 연속 메모리 할당
1. 연속 메모리 할당이란
    - 프로세스에 연속적인 메모리 공간을 할당하는 방식<br><br>

2. 스와핑
    - 스와핑(swapping) : 메모리에서 사용되지 않는 일부 프로세스를 보조기억장치로 내보내고 실행할 프로세스를 메모리로 들여보내는 메모리 관리 기법
    - 스왑 영역(swap space) : 프로세스들이 쫓겨나는 보조기억장치의 일부 영역
    - 스왑 아웃(swap-out) : 현재 실행되지 않는 프로세스가 메모리에서 스왑 영역으로 옮겨지는 것
    - 스왑 인(swap-in) : 스왑 영역에 있던 프로세스가 다시 메모리로 옮겨오는 것
        - 스왑 아웃되었던 프로세스가 다시 스왑 인될 때는 스왑 아웃되기 전의 물리 주소와는 다른 주소에 적재될 수 있음<br><br>

3. 메모리 할당
    - 메모리 할당이란
        - 메모리 공간에 프로세스를 연속적으로 할당하는 방식<br><br>

    - 메모리 할당 방식
        - 최초 적합(first fit) : 최초로 발견한 적재 가능한 빈 공간에 프로세스를 배치하는 방식
        - 최적 적합(best fit) : 프로세스가 적재될 수 있는 가장 작은 공간에 프로세스를 배치하는 방식
        - 최악 적합(worst fit) : 프로세스가 적재될 수 있는 가장 큰 공간에 프로세스를 배치하는 방식<br><br>

4. 외부 단편화(external fragmentation)
    - 외부 단편화란
        - 남아있는 메모리의 크기가 실행하고자 하는 프로세스보다 크지만, 연속적이지 않은 공간에 존재하여 실행하지 못해 메모리가 낭비되는 현상<br><br>

    - 외부 단편화 해결 방안
        - 압축(compaction) : 메모리 내에 저장된 프로세스를 적당히 재배치시켜 여기저기 흩어져 있는 작은 빈 공간들을 하나의 큰 빈 공간으로 만드는 방법
            - 작은 빈 공간들을 하나로 모으는 동안 시스템은 하던 일을 중지해야 하고, 메모리에 있는 내용을 옮기는 작업은 많은 오버헤드를 야기하며, 어떤 프로세스를 어떻게 움직여야 오버헤드를 최소화하며 압축할 수 있는지에 대한 명확한 방법을 결정하기 어려움<br><br>

5. 내부 단편화(internal fragmentation)
    - 내부 단편화란
        - 프로세스가 필요한 양보다 더 큰 메모리가 할당되어서 프로세스에서 사용하는 메모리 공간이 낭비되는 현상
        - 페이지 크기가 작다면 발생하는 내부 단편화의 크기는 작아질 것으로 기대
        - 단, 페이지 크기를 너무 작게 설정하면 그만큼 페이지 테이블의 크기도 커지기 때문에 페이지 테이블이 차지하는 공간이 낭비됨
        - 따라서, 내부 단편화 방지를 위해 너무 크지 않은 페이지 테이블이 만들어지도록 페이지의 크기를 조정하는 것이 중요<br><br>

## 2. 페이징을 통한 가상 메모리 관리
1. 프로세스를 메모리에 연속적으로 할당하는 방식의 두 가지 문제
    - 외부 단편화 발생
    - 물리 메모리보다 큰 프로세스를 실행할 수 없다는 점<br><br>

2. 가상 메모리(virtual memory)
    - 실행하고자 하는 프로그램을 일부만 메모리에 적재하여 실제 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있게 하는 기술<br><br>

3. 페이징(paging)
    - 페이징이란
        - 메모리의 물리 주소 공간을 프레임 단위로 자르고, 프로세스의 논리 주소 공간을 페이지 단위로 자른 뒤 페이지를 프레임에 할당하는 가상 메모리 관리 기법<br><br>

    - 페이지 아웃(page out)과 페이지 인(page in)
        - 페이지 아웃 = 스왑 아웃
            - 메모리에 적재될 필요가 없는 페이지들을 보조기억장치로 옮기는 것
        - 페이지 인 = 스왑 인
            - 실행에 필요한 페이지들을 메모리로 옮겨오는 것<br><br>

    - 프로세스가 메모리에 불연속적으로 배치되었을 때의 문제
        - CPU 입장에서 프로세스를 이루는 페이지가 어느 프레임에 적재되어 있는지 모두 알기 어려워 프로세스를 순차적으로 실행할 수 없음
        - 이를 해결하기 위해 페이지 테이블을 이용<br><br>

    - 페이지 테이블(page table)
        - 프로세스가 물리 주소(실제 메모리 내의 주소)에 불연속적으로 배치되더라도 논리 주소(CPU가 바라보는 주소)에는 연속적으로 배치되도록 함
        - 페이지 번호와 프레임 번호를 짝지어 주는 일종의 이정표로, CPU가 페이지 번호를 보고 해당 페이지가 적재된 프레임을 찾을 수 있게 함
        - 프로세스마다 각자의 프로세스 테이블을 보유
            - 각 프로세스의 페이지 테이블들은 메모리에 적재됨
            - CPU 내의 페이지 테이블 베이스 레지스터(PTBR, Page Table Base Register)는 각 프로세스의 페이지 테이블에 적재된 주소를 가리킴<br><br>

    - 페이지 테이블을 메모리에 두면 발생하는 문제
        - 메모리에 있는 페이지 테이블을 보기 위해 한 번, 그렇게 알게 된 프레임에 접근하기 위해 한 번 접근이 필요하여 메모리 접근 시간이 두 배로 늘어남
        - 이를 해결하기 위해 CPU 곁에(일반적으로 MMU 내에) TLB라는 페이지 테이블의 캐시 메모리를 둠<br><br>

    - TLB(Translation Lookaside Buffer)
        - 페이지 테이블의 캐시 메모리 역할을 수행하기 위해 페이지 테이블의 일부를 저장
            - 참조 지역성에 근거해 주로 최근에 사용된 페이지 위주로 가져와 저장
        - TLB 히트(TLB hit)
            - CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 있을 경우
            - 페이지가 적재된 프레임을 알기 위해 메모리에 접근할 필요가 없음 = 메모리 접근을 한 번만 수행
        - TLB 미스(TLB miss)
            - CPU가 발생한 논리 주소에 대한 페이지 번호가 TLB에 없는 경우
            - 페이지가 적재된 프레임을 알기 위해 메모리 내의 페이지 테이블에 접근해야 함<br><br>

4. 페이징에서의 주소 변환
    - 하나의 페이지 혹은 프레임은 여러 주소를 포괄하고 있어 특정 주소에 접근하려면 두 가지 정보가 필요
        - 어떤 페이지 혹은 프레임에 접근하고 싶은지의 정보
        - 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지의 정보<br><br>

    - 페이징 시스템에서는 모든 논리 주소가 기본적으로 페이지 번호와 변위로 구성
        - 가령 CPU가 32비트 주소를 내보냈다면 이 중 N비트는 페이지 번호, 32 - N비트는 변위
        - 페이지 번호(page number) : 접근하고자하는 페이지 번호
        - (offset) : 접근하려는 주소가 프레임의 시작 번지로부터 얼만큼 떨어져 있는지를 알기 위한 정보<br><br>

    - 논리 주소(페이지 번호, 변위)는 페이지 테이블을 통해 물리 주소(프레임 번호, 변위)로 변환
        - 예를 들어 CPU가 5번 페이지, 번위 2라는 논리 주소에 접근한다고 가정
            - 5번 페이지는 현재 1번 프레임에 있음
            - CPU는 1번 프레임, 번위 2에 접근
            - 1번 프레임은 8번지부터 시작하기 때문에 CPU는 10번지에 접근<br><br>

5. 페이지 테이블 엔트리(PTE, Page Table Entry)
    - 페이지 테이블 엔트리란
        - 페이지 테이블의 각각의 행들<br><br>

    - 페이지 테이블 엔트리에 담기는 정보
        - 페이지 번호, 프레임 번호 외에도 유효 비트, 보호 비트, 참조 비트, 수정 비트 등이 존재
        - 유효 비트(vaild bit)
            - 현재 해당 페이지에 접근 가능한지 여부를 알려줌
            - 현재 페이지가 메모리에 적재되어 있는지 아니면 보조기억장치에 있는지를 알려주는 비트
            - 페이지가 메모리에 적재되어 있다면 1, 아니라면 0
            - CPU가 유효 비트가 0인 메모리에 적재되어 있지 않은 페이지로 접근하려고 하면, 페이지 폴트(page fault)라는 예외(Exception)가 발생
                - 페이지 폴트를 처리하는 과정
                    - CPU는 기존 작업 내역을 백업
                    - 페이지 폴트 처리 루틴 실행
                    - 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경
                    - 페이지 폴트를 처리했다면 CPU는 해당 페이지에 접근 가능
        - 보호 비트(protection bit)
            - 페이지 보호 기능을 위해 존재하는 비트
            - 보호 비트를 통해 해당 페이지가 읽고 쓰기가 모두 가능한 페이지인지, 혹은 읽기만 가능한 페이지인지를 나타낼 수 있음
            - 0일 경우 읽기만 가능한 페이지, 1일 경우 읽고 쓰기가 모두 가능한 페이지
            - 읽기를 나타내는 r, 쓰기를 나타내는 w, 실행을 나타내는 x의 조합으로 읽기, 쓰기, 실행하기 권한의 조합을 나타낼 수 있음
        - 참조 비트(reference bit)
            - CPU가 이 페이지에 접근한 적이 있는지 여부를 나타냄
            - 적재 이후 CPU가 읽거나 쓴 페이지는 1로 세팅되고, 적재 이후 한 번도 읽거나 쓴 적이 없는 페이지는 0으로 유지
        - 수정 비트(modified bit) = 더티 비트(dirty bit)
            - 해당 페이지에 데이터를 쓴 적이 있는지 없는지 수정 여부를 알려줌
            - 1이면 변경된 적이 있는 페이지, 0이면 변경된 적이 없는 페이지(한 번도 접근한 적이 없거나 읽기만 했던 페이지)<br><br>

6. 페이징의 이점 : 쓰기 시 복사(copy on write)
    - 페이징에서는 COW(Copy On Write)가 발생
    - 프로세스에서 fork()와 exec()을 통해서 자식 프로세스를 만든다는 것을 알고 있음
    - 하지만, 그때마다 페이징 테이블도 복사한다면 비효율적임
    - COW는 이런 상황을 해소시켜주기 위해 바로 새로운 페이지 테이블을 복사 생성하지 않고 있다가, 진짜로 그 페이지 테이블을 사용할 일이 생길때(write 할 일이 생길 때) 그제서야 페이지 테이블 복사본을 생성함<br><br>

7. 계층적 페이징(hierarchical paging)
    - 프로세스의 크기가 커지면 자연히 프로세스 테이블의 크기도 커지기 때문에 프로세스를 이루는 모든 페이지 테이블 엔트리를 메모리에 두는 것은 큰 메모리 낭비임
    - 이런 메모리 낭비를 해소하기 위해 계층적 페이징이 등장
    - 계층적 페이징은 페이지 테이블을 페이징하여 여러 단계의 페이지를 두는 방식으로, 다단계 페이지 테이블(multilevel page table) 기법이라고도 함
        - 바깥쪽에 페이지 테이블을 하나 더 두어 잘린 페이지 테이블의 페이지들을 가리키게 하는 방식

## 3. 페이지 교체와 프레임 할당
1. 요구 페이징(demand paging)
    - 요구 페이징이란
        - 프로세스를 메모리에 적재할 때 처음부터 모든 페이지를 적재하지 않고 필요한 페이지만을 메모리에 적재하는 기법<br><br>

    - 요구페이징 과정
        - CPU가 특정 페이지에 접근하는 명령어를 실행
        - 해당 페이지가 현재 메모리에 있을 경우 CPU는 페이지가 적재된 프레임에 접근
        - 해당 페이지가 현재 메모리에 없을 경우 페이지 폴트가 발생
        - 페이지 폴트 처리 루틴은 해당 페이지를 메모리로 적재하고 유효 비트를 1로 설정
        - 다시 첫 번째 과정 수행<br><br>

    - 순수 요구 페이징(pure demand paging)
        - 아무런 페이지도 메모리에 적재하지 않은 채 실행하는 기법
        - 프로세스의 첫 명령어를 실행하는 순간부터 페이지 폴트가 계속 발생
        - 실행에 필요한 페이지가 어느 정도 적재된 이후부터는 페이지 폴트 발생 빈도가 감소<br><br>

    - 요구 페이징 시스템을 안정적으로 작동하기 위해 해결해야할 두 가지
        - 페이지 교체 & 프레임 할당<br><br>

2. 페이지 교체 알고리즘(Page Replacement Algorithm)
    - 페이지 교체 알고리즘이란
        - 쫓아낼 페이지를 결정하는 방법
        - 요구 페이징 기법으로 페이지들을 적재하다 보면 언젠가 메모리가 가득 참
        - 당장 실행에 필요한 페이지를 적재하기 위해 메모리에 적재된 페이지를 보조기억장치로 내보내야 함
        - 즉, 메모리에 적재된 페이지들 중 어떤 페이지를 내보내는 것이 최선인지 결정하는 방법<br><br>

    - 좋은 페이지 교체 알고리즘이란
        - 페이지 프로트를 가장 적게 일으키는 알고리즘
        - 페이지 폴트가 발생하면 보조기억장치로부터 필요한 페이지를 가져와야 하기 때문에 메모리에 적재된 페이지를 가져오는 것보다 느리기 때문임<br><br>

    - 페이지 폴트 횟수
        - 페이지 참조열을 통해 알 수 있음
            - 페이지 참조열(page reference string) : CPU가 참조하는 페이지들 중 연속된 페이지를 생략한 페이지열
                - CPU가 2 2 2 3 5 5 5 3 3 7 순서로 페이지에 접근했다면, 페이지 참조열은 2 3 5 3 7
                - 연속된 페이지를 생략하는 이유는 중복된 페이지를 참조하는 행위는 페이지 폴트를 발생시키지 않기 때문임<br><br>

    - 페이지 교체 알고리즘 종류
        - FIFO 페이지 교체 알고리즘(First-In First-Out Page Replacement Algorithm)
            - 적재된 페이지 순서대로 교체하는 알고리즘
            - 자주 참조되는 페이지가 먼저 적재되었다는 이유만으로 내쫓길 수 있다는 문제가 있음<br><br>

        - 2차 기회 페이지 교체 알고리즘(Second-Chance Page Replacement Algorithm)
            - FIFO 페이지 교체 알고리즘의 부작용을 어느 정도 개선한 알고리즘
            - 메모리에서 가장 오래 머물럿던 페이지를 대상으로 내보낼 페이지를 선별
            - 메모리에 가장 오래 머무른 페이지의 참조 비트가 1일 경우, 당장 내쫓지 않고 참조 비트를 0으로 만든 뒤 현재 시간을 적재 시간으로 설정
                - 메모리에 가장 오래 머물럿다고 해서 참조 비트가 1 이라면, CPU가 접근한 적이 있다는 것으로 한 번의 기회를 더 주는 것
            - 만일 페이지의 참조 비트가 0일 경우, 이 페이지는 가장 오래된 페이지이면서 동시에 사용하지 않은 페이지라고 불 수 있으므로 보조기억장치로 내보냄<br><br>

        - 최적 페이지 교체 알고리즘(Optimal Page Replacement Algorithm)
            - 앞으로의 사용 빈도가 낮은 페이지를 교체하는 알고리즘
            - 가장 낮은 페이지 푤트율을 보장하는 알고리즘
            - '앞으로 오랫동안 사용되지 않을 페이지'를 예측하기란 현실적으로 불가능에 가깝기 때문에 구현이 어려움
            - 운영체제에 사용하기 보단 다른 페이지 교체 알고리즘의 이론상 성능 평가 목적으로 사용<br><br>

        - LRU 페이지 교체 알고리즘(Least Recently Used Page Replacement Algorithm)
            - 가장 오랫동안 사용되지 않은 페이지를 교체하는 알고리즘<br><br>

3. 스레싱과 프레임 할당
    - 페이지 폴트가 자주 발생하는 다른 이유
        - 프로세스가 사용할 수 있는 프레임 수가 적어도 페이지 폴트가 자주 발생
        - 프레임이 부조가면 페이지 폴트가 자주 발생할 수 밖에 없음 → CPU 이용률이 감소<br><br>

    - 스레싱(thrashing)이란
        - 지나치게 빈번한 페이지 교체로 인해 CPU 이용률이 낮아지는 문제로, 각 프로세스가 필요로 하는 최소한의 프레임 수가 보장되지 않아서 발생
            - 운영체제는 각 프로세스들이 무리 없이 실행하기 위한 최소한의 프레임 수를 파악하고 프로세스들에 적절한 수만큼 프레임을 할당해 줄 수 있어야 함
        - 메모리에 동시 실행되는 프로세스의 수를 멀티프로그래밍의 정도(degree of multiprogramming)라고 함
            - 멀티프로그래밍의 정도가 늘어나면 CPU 이용률이 높아지지만, 필요 이상으로 늘리면 프로세스들이 사용할 수 있는 프레임 수가 적어지기 때문에 페이지 폴트 발생율이 증가하여 CPU의 이용률이 감소<br><br>

    - 프레임 할당 방식
        - 정적 할당 방식 : 프로세스의 실행 과정을 고려하지 않고 단순히 프로세스의 크기와 물리 메모리의 크기만을 고려한 방식
            - 균등 할당(equal allocation) : 모든 프로세스에 동일한 프레임을 배분하는 방식
            - 비례 할당(proportional allocation) : 프로세스 크기에 따라 프레임을 배분하는 방식
        - 동적 할당 방식 : 프로세스의 실행을 보고 할당할 프레임 수를 결정하는 방식
            - 작업 집합 모델(working set model) : '프로세스가 일정 기간 동안 페이지 집합'을 기억하여 빈번한 페이지 교체를 방지하는 방식
                - 작업 집합의 크기만큼만 프레임을 할당하는 방식
                    - 작업 집합(working set) : 실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합
            - 페이지 폴트 빈도(PFF, Page Fault Frequency) : 아래 두 개의 가정에서 생겨는 아이디어
                - 페이지 폴트율이 너무 높으면, 그 프로세스는 너무 적음 프레임을 갖고 있음
                    - 페이지 폴트율이 페이지 폴트율의 상한선보다 더 높으면, 해당 프로세스는 너무 적은 프레임을 갖고 있다고 볼 수 있음
                    - 따라서, 해당 프로세스에 프레임을 더 할당
                - 페이지 폴트율이 너무 낮으면, 그 프로세스는 너무 많은 프레임을 갖고 있음
                    - 페이지 폴트율이 페이지 폴트율의 하한선보다 더 낮다면, 해당 프로세스는 너무 많은 프레임을 갖고 있다고 볼 수 있음
                    - 따라서, 해당 프로세스에 할당된 프레임을 회수<br><br>

## 4. 세그멘테이션(segmentation)
1. 동적 재배치의 한계
    - 프로그램의 전체 주소공간을 물리 메모리에 탑재하여 발생하는 내부 단편화
        - 힙과 스택 사이의 큰 빈공간
        - 32비트 컴퓨터의 경우 4GB의 주소공간을 가짐
        - 프로그램은 실제 메가바이트에 그치지만, 4GB로 모두 물리메모리에 올려야해서 유연성이 떨어짐<br><br>

2. 세그멘테이션 : 베이스/바운드(base/bound)의 일반화
    - 세그멘테이션이란
        - 프로세스가 할당받은 메모리 공간을 논리 의미 단위인 세그멘트(segment)로 나뉘어 연속되지 않는 물리 메모리 공간에 할당될 수 있도록 하는 메모리 관리 기법
        - MMU에 하나의 베이스와 바운드 값이 존재하는 것이 아닌 세그멘트마다 베이스와 바운드 값이 존재
        - 운영체제는 각 세그멘트를 물리 메모리의 각기 다른 위치에 배치할 수 있어 내부 단편화를 방지할 수 있음<br><br>

    - 세그멘트란
        - 특정 길이를 가지는 연속적인 주소 공간
        - 대표적으로 코드, 스택, 힙이 있음<br><br>

    - 가상 주소 공간을 물리 주소로 변환하는 과정
        - 가상 주소 4200의 힙을 물리 주소로 변환한다고 가정
        - 가상 주소 4200을 힙의 베이트(34KB)에 더하면 물리 주소 39016을 얻지만, 올바른 물리 주소가 아님
        - 힙 안에서의 오프셋, 즉 주소가 참조하는 바이트가 이 세그멘트 시작으로부터 몇 번째 바이트인지를 얻어야 함
        - 힙은 가상 주소 4KB(4096)에서 시작하기 때문에 오프셋은 4200 빼기 4096, 즉 104가 됨
        - 오프셋(104)을 베이스 레지스터의 물리 주소(34KB)에 더해 원하는 결과 34920을 얻게 됨
        - 만일 힙의 마지막을 벗어난 (가상 주소로 7KB 보다 먼) 주소를 접근하려고 한다면, 세그멘트 폴트(segment fault)가 발생<br><br>

3. 세그멘트 종류의 파악
    - 하드웨어는 가상 주소를 보고 세그멘트의 종류가 무엇인지 알 수 있어야 하고 해당 세그멘트 안에서 오프셋이 얼마인지 알 수 있어야 함
        - 16KB의 가상 주소 공간을 가정했다면, 14비트로 주소를 나타낼 수 있음
        - 상위 2비트는 세그멘트의 종류를 나타냄
        - 하위 12비트는 오프셋을 나타냄
        - 오프셋이 바운드보다 작은지 검사하여 유효한 주소인지 검사<br><br>

4. 스택
    - 다른 세그멘트들과의 차이점
        - 낮은 주소 방향으로 다른 세그멘트들과는 반대 방향으로 확장
        - 따라서, 하드웨어는 세그멘트가 주소공간 내에서 확장하는 방향에 대해서도 알고 있어야 함
        - 이를 위해 하나의 비트를 사용하여 양의 방향과 음의 방향을 구분함<br><br>

5. 공유 지원
    - 메모리를 절약하기 위해 간단한 하드웨어 자원을 통해 메모리 세그멘트를 공유할 수 있게 되었음
    - 특히 코드영역 공유는 현재 시스템에서도 광범위하게 사용 중
    - protection bit를 추가하여 읽기/쓰기/실행과 같은 권한을 설정 할 수 있음
    - 권한을 설정할 수 있게 되면 코드 세그먼트를 읽기 권한으로 설정하면 주소 공간의 독립성을 유지하면서도 여러 프로세스가 주소 공간의 일부를 안전하게 공유할 수 있게 됨<br><br>

6. 세그멘테이션의 한계
    - 세그멘테이션은 내부 단편화는 해결하였지만 각 세그멘트의 크기가 일정하지 않기 때문에 외부 단편화를 유발하여 물리 메모리 내에 작은 빈공간들이 계속 생기게 됨
    - 압축을 사용하면 어느정도 문제를 해결할 수 있지만 세그먼트를 복사하여 새로운 곳으로 이동 시키는 것은 메모리 부하가 큰 연산이고 상당량의 프로세서 시간을 사용하기 때문에 비용이 많이 듦
    - 빈공간 리스트를 관리하는 알고리즘을 사용하면 어느정도 문제를 해결할 수 있지만 아무리 좋은 알고리즘이라도 여전히 외부 단편화는 존재하게 됨
    - 이를 해결하기 위헤 페이징 기법을 사용